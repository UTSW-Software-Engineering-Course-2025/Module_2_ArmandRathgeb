{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e2a037",
   "metadata": {},
   "source": [
    "# conditional Auxillary Classifier GAN\n",
    "Train an auxillary classifier GAN on the MNIST handwritten digit dataset. \n",
    "\n",
    "This makes use of: our custom Keras model class defined in\n",
    "vaegan.gan.py, our class for loading the MNIST dataset defined in\n",
    "vaegan.data, and our custom Keras callback in vaegan.conditional.callbacks.\n",
    "\n",
    "A directory called 'output' will be created to save figures and the trained\n",
    "model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nEpochs=20  # orig, longer training\n",
    "nEpochs=3  # quick testing during development\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "597a6418",
   "metadata": {},
   "source": [
    "## 1. Import 3rd party libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "# Import our own classes \n",
    "from vaegan.data import MNIST\n",
    "from vaegan.conditional.callbacks import GenerateImagesConditional\n",
    "from vaegan.gan import ConditionalGAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e9587ca",
   "metadata": {},
   "source": [
    "## 3. Show some our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist yet.\n",
    "output_dir = './outputs/mnist_cgan'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "# Instantiate the MNIST class containing our training data.\n",
    "data = MNIST()\n",
    "\n",
    "# One-hot encode the labels\n",
    "n_classes = int(data.labels_train.max() + 1)\n",
    "labels_onehot = tf.one_hot(data.labels_train, \n",
    "                           depth=n_classes,\n",
    "                           dtype=tf.float32).numpy()\n",
    "\n",
    "# Show some example images and their labels.\n",
    "data.show_example_images(os.path.join(output_dir, 'example_images.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90614cbf",
   "metadata": {},
   "source": [
    "## 4. Construct the model using the python class you completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model. Note that we're using mostly the default arguments, but this is\n",
    "# where you might want to play around with different loss weights.\n",
    "tf.random.set_seed(1234)\n",
    "model = ConditionalGAN(n_classes=n_classes)\n",
    "\n",
    "# This step tells Keras to compute the explicit output shapes of each layer.\n",
    "# Otherwise, the layers will have dynamic/variable output shapes which is not\n",
    "# compatible with saving and loading.\n",
    "model.compute_output_shape([(None, 32, 32, 1), (None, n_classes)])\n",
    "model.discriminator.compute_output_shape((None, 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== OVERALL MODEL ====\")\n",
    "model.summary()\n",
    "print(\"=== GENERATOR SUBMODEL ====\")\n",
    "gen_in = tf.keras.layers.Input(model.n_latent_dims+n_classes)\n",
    "gen_out  = model.generator.call(gen_in) \n",
    "gen = tf.keras.Model(gen_in, gen_out) \n",
    "gen.summary()\n",
    "print(\"=== DISCRIMINATOR SUBMODEL ====\")\n",
    "disc_in = tf.keras.layers.Input(model.image_shape) \n",
    "disc_out  = model.discriminator.call(disc_in) \n",
    "disc = tf.keras.Model(disc_in, disc_out) \n",
    "disc.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f713d73",
   "metadata": {},
   "source": [
    "## 6. Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea33040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with an optimizer. The learning rate of the optimizer can be\n",
    "# specified here. Normally, this is also where you would select a loss function\n",
    "# and any metrics. However, our custom model defines the loss functions inside\n",
    "# its __init__ constructor, so we don't need to do that here. \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "\n",
    "# Instantiate our custom callback to save a few example reconstructions and\n",
    "# generated images after each epoch.\n",
    "save_images_callback = GenerateImagesConditional(output_dir=output_dir, \n",
    "                                                 model=model,\n",
    "                                                 example_labels=labels_onehot[:10],\n",
    "                                                 n_generated_images=10,\n",
    "                                                 n_latent_dims=model.n_latent_dims)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e13f46",
   "metadata": {},
   "source": [
    "## 7. Train (fit) the model on the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model. Just like any off-the-shelf Keras model, we just call fit.\n",
    "# Under the hood, Keras will call the train_step method of our custom subclass\n",
    "# on each mini-batch and automatically loop through the training data. It will\n",
    "# take care of all the details, like converting numpy arrays to tensors, showing\n",
    "# a progress bar, and tracking the loss over the epochs.\n",
    "logs = model.fit([data.images_train, labels_onehot],\n",
    "                 batch_size=128,\n",
    "                 epochs=nEpochs,\n",
    "                 callbacks=[save_images_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "017937af",
   "metadata": {},
   "source": [
    "## 8. Training saves results to disk, now also plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dccd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves, which are stored in logs.history as a dict. Keys of\n",
    "# this dict are the metric names, while the corresponding values are arrays.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for loss_name in ['gen_loss', 'disc_loss']:\n",
    "    loss_values = logs.history[loss_name]\n",
    "    x = np.arange(len(loss_values))\n",
    "    ax.plot(x, loss_values, label=loss_name)\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "fig.savefig(os.path.join(output_dir, 'training_curves.png'), transparent=False)\n",
    "# fig.show()\n",
    "\n",
    "# Save the model \n",
    "model.save(os.path.join(output_dir, 'cgan'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd69e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "276cb92f24b41b9f0d970b9341f6985e33d08dd20600905fc8ace2fed9003440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
